‚úçWhat are Data Structures?
- A way to store, organize & manage information(or data) in a way that allows you
the programmer to easily access or modify the values within them.
- Provide backbone to the programs
- Store information & access & manipulate information effectively
- Basic Data structures like => Password & online directories,etc
- Advanced Data structures Like => Autocomplete of text messages, undo, redo functions, etc
- Efficiency => the metrics used to judge the speed & Efficiency of different data structures
 
‚úçSeries Overview
üíª Arrays
üíª ArrayLists
üíª Stacks
üíª Queues
üíª LinkedLists
üíª Doubly-LinkedLists
üíª Dictionaries
üíª Hash-Tables
üíª Trees
üíª Tries
üíª Heaps
üíª Graphs

üíª (06:55) Measuring Efficiency with BigO Notation
- Quantifiable way to measure to how efficient certain data structures are at different tasks we might as of it 
 - Searching through
 - Modifying
 - Access
- The industry standard for this kind of measurement => BigO Notation
- BigO Notation => Based on four criteria
  - Accessing elements
  - Searching elements
  - Inserting elements
  - Deleting elements 
‚å®Ô∏è (09:45) Time Complexity Equations
   - Works by Inserting the size of the data-set as an integer n, and returning the number of operations that need to be conducted by the computer before the function can finish
   - The number of operations that need to be conducted by the computer before completion of that function
   - We always use the worst-case scenario when judging these data structures
‚å®Ô∏è (11:13) The Meaning of BigO
   - The syntax for the time complexity equations included a BigO and then a set of parenthesis
     - The parenthesis houses the function
     - A random function and its time complexity is measured based on the data sets, our integer n
     - n => number of operations
     - More data set => More instructions
‚å®Ô∏è (12:42) Why BigO?
     - We measure Efficiency in # of operations performed because measuring by how long the function takes to run would be silly => Measuring by time is biased towards better hardware
‚å®Ô∏è (13:18) Quick Recap
    - Measure Efficiency based on 4 metrics => Accessing, Searching, Inserting, Deleting
    - Modeled by an equation which takes in size of data-set n => number of operations needed to perform the task
‚å®Ô∏è (14:27) Types of Time Complexity Equations
    - O(1) =>Constant algorithm, absolute best, no matter what the size of your data set is , the task will be completed in a single instruction
    - O(log n) => Logarithmic algorithm, Next fastest type of time complexity, fast completion time, more efficient
    - O(n) => Linear algorithm Common time complexity, the last of the decent equations
    - O(n log n) => Relatively Bad
    - O(n2)=> Polynomial algorithm, Very bad in terms of Efficiency 
    - O(2n)=> Exponential algorithm, Very bad in terms of Efficiency
‚å®Ô∏è (19:42) Final Note on Time Complexity Equations
    - Time complexity equations are NOT the only metric you should be using the gauge which data structure to use 
    - Some provide other functionality that make them extremely useful
    
üíª (20:21) The Array
    - A pretty common data structure taught in most programming classes 

‚å®Ô∏è (20:58) Array Basics
    - fundamentally a list of similar values
    - can be store anything => usernames, high scores, prices, etc.
    - store values of the same data type => integer, float ,etc.
    - item referred to as "element"
    - three attributes => A name , A Type , A size 

‚å®Ô∏è (22:09) Array Names
    - Array Names => name of the array, used to reference & interact with it
      Example: Names =  ["John Smith", "Gary Vee"]; Salaries = [10000, 12400]

‚å®Ô∏è (22:59) Parallel Arrays
    - Two or more arrays which => contain the same no. of elements => have corresponding values in the same position
    - extremely useful for storing different types of data about the same entity

‚å®Ô∏è (23:59) Array Types
    - what type of information is stored or will be stored within that array
    - has to hold all the same type of information

‚å®Ô∏è (24:30) Array Size
    - Immutable 
    - a set integer that is fixed upon creation of the array
    - represents the total amount of elements that are able to be stored within the array

‚å®Ô∏è (25:45) Creating Arrays
    - 2 different ways to create an array in most languages
     => populate the array with elements right then & there
     => set a specific size for the array, then populate it later

‚å®Ô∏è (26:11) Populate-First Arrays
    - defining & filling an array as soon as you create it is used mainly for when you already know which values are going to be held within it
    - The way varies from languages => Java, Python, C#
     => int array[] = {1,2,3}; //Java 
     => array =[1,2,3]         // Python
     => int[] array = {1,2,3}; // C#

‚å®Ô∏è (28:09) Populate-Later Arrays
    - creating an array by setting an initial size for our array, but not filing it with any elements
     => slowly populate it as the programs run
     => used for user-entered information
     => int array [] =new int[10]; // Java
     => int[] arrray = new int[10]; // C#

‚å®Ô∏è (30:22) Numerical Indexes
    - get information that is stored withing the array, we use a number Indexes
    - an integer which corresponds to an element within the array

‚å®Ô∏è (31:57) Replacing information in an Array
    - Referencing an arrays index is also h0w we replace elements within an array

‚å®Ô∏è (32:42) 2-Dimensional Arrays
    - an array with an array at each index is known as a 2-Dimensional array
    - useful for programming chessboard, bingo board, image with rgb values,etc
    - includes 2 indexes => one for the column and other with row
    - there are 3d arrays and 4d arrays for complex programming

‚å®Ô∏è (35:01) Arrays as a Data Structure
    - accessing, searching, inserting, deleting in an array
    -  O(1), 
‚å®Ô∏è (42:21) Pros and Cons
üíª (43:33) The ArrayList
‚å®Ô∏è (44:42) Structure of the ArrayList
‚å®Ô∏è (45:19) Initializing an ArrayList
‚å®Ô∏è (47:34) ArrayList Functionality
‚å®Ô∏è (49:30) ArrayList Methods
‚å®Ô∏è (50:26) Add Method
‚å®Ô∏è (53:57) Remove Method
‚å®Ô∏è (55:33) Get Method
‚å®Ô∏è (55:59) Set Method
‚å®Ô∏è (56:57) Clear Method
‚å®Ô∏è (57:30) toArray Method
‚å®Ô∏è (59:00) ArrayList as a Data Structure
‚å®Ô∏è (1:03:12) Comparing and Contrasting with Arrays
üíª (1:05:02) The Stack
‚å®Ô∏è (1:05:06) The Different types of Data Structures
‚å®Ô∏è (1:05:51) Random Access Data Structures
‚å®Ô∏è (1:06:10) Sequential Access Data Structures
‚å®Ô∏è (1:07:36) Stack Basics
‚å®Ô∏è (1:09:01) Common Stack Methods
‚å®Ô∏è (1:09:45) Push Method
‚å®Ô∏è (1:10:32) Pop Method
‚å®Ô∏è (1:11:46) Peek Method
‚å®Ô∏è (1:12:27) Contains Method
‚å®Ô∏è (1:13:23) Time Complexity Equations
‚å®Ô∏è (1:15:28) Uses for Stacks
üíª (1:18:01) The Queue
‚å®Ô∏è (1:18:51) Queue Basics
‚å®Ô∏è (1:20:44) Common Queue Methods
‚å®Ô∏è (1:21:13) Enqueue Method
‚å®Ô∏è (1:22:20) Dequeue Method
‚å®Ô∏è (1:23:08) Peek Method
‚å®Ô∏è (1:24:15) Contains Method
‚å®Ô∏è (1:25:05) Time Complexity Equations
‚å®Ô∏è (1:27:05) Common Queue Uses
üíª (1:28:16) The Linked List
‚å®Ô∏è (1:31:37) LinkedList Visualization
‚å®Ô∏è (1:33:55) Adding and Removing Information
‚å®Ô∏è (1:41:28) Time Complexity Equations
‚å®Ô∏è (1:44:26) Uses for LinkedLists
üíª (1:47:19) The Doubly-LinkedList
‚å®Ô∏è (1:48:44) Visualization
‚å®Ô∏è (1:50:56) Adding and Removing Information
‚å®Ô∏è (1:58:30) Time Complexity Equations
‚å®Ô∏è (1:59:06) Uses of a Doubly-LinkedList
üíª (2:00:21) The Dictionary
‚å®Ô∏è (2:01:15) Dictionary Basics
‚å®Ô∏è (2:02:00) Indexing Dictionaries
‚å®Ô∏è (2:02:40) Dictionary Properties
üíª (2:05:53) Hash Table Mini-Lesson
‚å®Ô∏è (2:13:26) Time Complexity Equations
üíª (2:16:39) Trees
‚å®Ô∏è (2:16:55) Introduction to Hierarchical Data
‚å®Ô∏è (2:18:54) Formal Background on the Tree
‚å®Ô∏è (2:20:03) Tree Terminology and Visualization
‚å®Ô∏è (2:25:08) Different types of Trees
‚å®Ô∏è (2:28:07) Uses for the Tree
üíª (2:29:00) Tries
‚å®Ô∏è (2:29:50) Trie Basics
‚å®Ô∏è (2:30:41) Trie Visualization
‚å®Ô∏è (2:34:33) Flagging
‚å®Ô∏è (2:35:15) Uses for Tries
üíª (2:38:25) Heaps
‚å®Ô∏è (2:38:51) Heap Basics
‚å®Ô∏è (2:39:19) Min-Heaps
‚å®Ô∏è (2:40:07) Max-Heaps
‚å®Ô∏è (2:40:59) Building Heaps
‚å®Ô∏è (2:44:20) Deleting from Heaps
‚å®Ô∏è (2:46:00) Heap Implementations
üíª (2:48:15) Graphs
‚å®Ô∏è (2:49:25) Graph Basics
‚å®Ô∏è (2:52:04) Directed vs. Undirected Graphs
‚å®Ô∏è (2:53:45) Cyclic vs. Acyclic Graphs
‚å®Ô∏è (2:55:04) Weighted Graphs
‚å®Ô∏è (2:55:46) Types of Graphs
üíª (2:58:20) Conclusion